{"cells":[{"cell_type":"code","execution_count":1,"id":"f2915cc1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32913,"status":"ok","timestamp":1713978890535,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"},"user_tz":-330},"id":"f2915cc1","outputId":"883b73d3-5e57-40dd-c85e-9d4977d0d37e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"id":"e66283ff","metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1713978890537,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"},"user_tz":-330},"id":"e66283ff","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da1f75c3-9185-446b-c333-1e3dea25b2fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/SER/implementations/pepino21_interspeech\n"]}],"source":["%cd 'gdrive/MyDrive/SER/implementations/pepino21_interspeech/'"]},{"cell_type":"code","source":["!pip uninstall torch torchaudio torchvision torchtext -y"],"metadata":{"id":"qIfWBhom0gvF","executionInfo":{"status":"ok","timestamp":1713978907638,"user_tz":-330,"elapsed":17119,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12106356-5d0f-458e-e3aa-ae89d9e32ef1"},"id":"qIfWBhom0gvF","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.2.1+cu121\n","Uninstalling torch-2.2.1+cu121:\n","  Successfully uninstalled torch-2.2.1+cu121\n","Found existing installation: torchaudio 2.2.1+cu121\n","Uninstalling torchaudio-2.2.1+cu121:\n","  Successfully uninstalled torchaudio-2.2.1+cu121\n","Found existing installation: torchvision 0.17.1+cu121\n","Uninstalling torchvision-0.17.1+cu121:\n","  Successfully uninstalled torchvision-0.17.1+cu121\n","Found existing installation: torchtext 0.17.1\n","Uninstalling torchtext-0.17.1:\n","  Successfully uninstalled torchtext-0.17.1\n"]}]},{"cell_type":"code","source":["!pip install torch==1.11.0 torchaudio==0.11.0 torchvision==0.12.0 torchtext==0.12.0"],"metadata":{"id":"ONWOuOGn0ghT","executionInfo":{"status":"ok","timestamp":1713978952141,"user_tz":-330,"elapsed":44526,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff6d1dfd-3872-4f69-c8ae-d2c54943f78e"},"id":"ONWOuOGn0ghT","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.11.0\n","  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.11.0\n","  Downloading torchaudio-0.11.0-cp310-cp310-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0\n","  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext==0.12.0\n","  Downloading torchtext-0.12.0-cp310-cp310-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.11.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (4.66.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2024.2.2)\n","Installing collected packages: torch, torchvision, torchtext, torchaudio\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0 torchaudio-0.11.0 torchtext-0.12.0 torchvision-0.12.0\n"]}]},{"cell_type":"code","source":["!pip install opensmile"],"metadata":{"id":"jEzzZ4iGFTBC","executionInfo":{"status":"ok","timestamp":1713978960412,"user_tz":-330,"elapsed":8323,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6560164-4b31-4541-9136-736f7d2a90a1"},"id":"jEzzZ4iGFTBC","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opensmile\n","  Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting audobject>=0.6.1 (from opensmile)\n","  Downloading audobject-0.7.11-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting audinterface>=0.7.0 (from opensmile)\n","  Downloading audinterface-1.2.1-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting audeer>=1.18.0 (from audinterface>=0.7.0->opensmile)\n","  Downloading audeer-2.0.0-py3-none-any.whl (39 kB)\n","Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n","  Downloading audformat-1.1.2-py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n","  Downloading audiofile-1.4.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting audmath>=1.3.0 (from audinterface>=0.7.0->opensmile)\n","  Downloading audmath-1.4.0-py3-none-any.whl (23 kB)\n","Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n","  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (7.1.0)\n","Collecting oyaml (from audobject>=0.6.1->opensmile)\n","  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (24.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audeer>=1.18.0->audinterface>=0.7.0->opensmile) (4.66.2)\n","Collecting iso-639 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n","  Downloading iso-639-0.4.5.tar.gz (167 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n","  Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.1)\n","Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.25.2)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.12.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.18.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2024.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.16.0)\n","Building wheels for collected packages: iso-639\n","  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168840 sha256=0bfca68f4f12df2fe98ae444db88d4d9a12198be614317184a8bb65b926d91bd\n","  Stored in directory: /root/.cache/pip/wheels/d8/78/cc/5478ca3b1c3f602eae6f8cdbd78f909c0a0bfa0bbcb5c7771f\n","Successfully built iso-639\n","Installing collected packages: iso-639, oyaml, iso3166, audresample, audmath, audeer, audobject, audiofile, audformat, audinterface, opensmile\n","Successfully installed audeer-2.0.0 audformat-1.1.2 audinterface-1.2.1 audiofile-1.4.0 audmath-1.4.0 audobject-0.7.11 audresample-1.3.3 iso-639-0.4.5 iso3166-2.1.1 opensmile-2.5.0 oyaml-1.0\n"]}]},{"cell_type":"code","execution_count":6,"id":"07acd18d","metadata":{"id":"07acd18d","executionInfo":{"status":"ok","timestamp":1713978964027,"user_tz":-330,"elapsed":3678,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.optim.lr_scheduler import ExponentialLR\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from dataset_classes.ravdess import MergeCalmAndNeutralRAVDESS, MyResample, RavdessAudio\n","from models.dense.pt_all2 import PreTrainedAllLayers"]},{"cell_type":"code","execution_count":7,"id":"23d829c3","metadata":{"id":"23d829c3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713978964034,"user_tz":-330,"elapsed":37,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"e5f3b468-9e7a-486a-9290-7e2d48fdb193"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}],"source":["device = torch.device('cpu')\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","\n","device"]},{"cell_type":"code","execution_count":8,"id":"dda10a37","metadata":{"id":"dda10a37","executionInfo":{"status":"ok","timestamp":1713978964036,"user_tz":-330,"elapsed":29,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["def my_collate_fn(batch):\n","    sample_list = [sample[0] for sample in batch]\n","    batch_tensor = pad_sequence(sample_list, batch_first=True)\n","    lengths = torch.tensor([sample[1] for sample in batch], dtype=torch.int)\n","    samp_rates = torch.tensor([sample[2] for sample in batch], dtype=torch.int)\n","    spkr_ids = torch.tensor([sample[3] for sample in batch], dtype=torch.int)\n","    labels = torch.tensor([sample[4] for sample in batch], dtype=torch.long)\n","    return batch_tensor, lengths, samp_rates, spkr_ids, labels"]},{"cell_type":"code","execution_count":9,"id":"f610d66c","metadata":{"id":"f610d66c","executionInfo":{"status":"ok","timestamp":1713978964037,"user_tz":-330,"elapsed":28,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["def train_epoch(dataloader, model, loss_fn, optimizer, print_every, lr_scheduler):\n","    \"\"\"\n","    print_every: after how many batches to print loss (on the last processed batch)\n","    \"\"\"\n","    num_samples = len(dataloader.dataset)\n","    samples_done = 0\n","    for batch_idx, batch in enumerate(dataloader):\n","        model_inp = tuple(batch[i].to(device) for i in range(4))\n","        labels = batch[4].to(device)\n","\n","        preds = model(model_inp)\n","        loss = loss_fn(preds, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        samples_done += model_inp[0].size(0)\n","        if (batch_idx+1)%print_every == 0:\n","            print(f\"loss: {loss:.5f}    [{samples_done:4d}/{num_samples:4d}]\")\n","    lr_scheduler.step()"]},{"cell_type":"code","execution_count":10,"id":"fdf7a63b","metadata":{"id":"fdf7a63b","executionInfo":{"status":"ok","timestamp":1713978964039,"user_tz":-330,"elapsed":26,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["def test_epoch(dataloader, num_classes, model, loss_fn):\n","    num_batches = len(dataloader)\n","    num_samples = len(dataloader.dataset)\n","\n","    loss = 0\n","    acc = 0\n","    tp = torch.zeros((num_classes))\n","    gnd_trth_p = torch.zeros((num_classes))\n","\n","    model.eval()\n","    for batch in dataloader:\n","        model_inp = tuple(batch[i].to(device) for i in range(4))\n","        labels = batch[4].to(device)\n","\n","        with torch.no_grad():\n","            preds = model(model_inp)\n","            loss += loss_fn(preds, labels).item()\n","            preds = preds.argmax(dim=1)\n","            acc += (preds == labels).sum().item()\n","            for i in range(num_classes):\n","                tp[i] += torch.logical_and(preds==i, labels==i).sum().item()\n","                gnd_trth_p[i] += (labels == i).sum().item()\n","    model.train()\n","\n","    loss /= num_batches\n","    acc /= num_samples\n","    recall = tp/gnd_trth_p\n","    avg_recall = torch.mean(recall)\n","    print(\"Test Error:\")\n","    print(f\"    loss: {loss:.5f}, acc: {100*acc:.2f} %\\n    avg recall: {100*avg_recall:.2f} %\")\n","    return loss"]},{"cell_type":"code","source":["train_dataset = RavdessAudio(dir_path=\"../../datasets/\",\n","                             csv_path=\"../../datasets/RAVDESS/my_stuff/train_csv.csv\",\n","                             transform=MyResample(48000, 16000),\n","                             target_transform=MergeCalmAndNeutralRAVDESS())\n","\n","val_dataset = RavdessAudio(dir_path=\"../../datasets/\",\n","                           csv_path=\"../../datasets/RAVDESS/my_stuff/val_csv.csv\",\n","                           transform=MyResample(48000, 16000),\n","                           target_transform=MergeCalmAndNeutralRAVDESS())\n","\n","test_dataset = RavdessAudio(dir_path=\"../../datasets/\",\n","                            csv_path=\"../../datasets/RAVDESS/my_stuff/test_csv.csv\",\n","                            transform=MyResample(48000, 16000),\n","                            target_transform=MergeCalmAndNeutralRAVDESS())\n","\n","num_classes = 7"],"metadata":{"id":"kXW0YiCeeVYB","executionInfo":{"status":"ok","timestamp":1713978970120,"user_tz":-330,"elapsed":6105,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"id":"kXW0YiCeeVYB","execution_count":11,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset,\n","                                               batch_size=batch_size,\n","                                               collate_fn=my_collate_fn,\n","                                               shuffle=True,\n","                                               generator=torch.Generator(device))\n","\n","val_dataloader = torch.utils.data.DataLoader(val_dataset,\n","                                             batch_size=batch_size,\n","                                             collate_fn=my_collate_fn,\n","                                             shuffle=True,\n","                                             generator=torch.Generator(device))\n","\n","test_dataloader = torch.utils.data.DataLoader(test_dataset,\n","                                              batch_size=batch_size,\n","                                              collate_fn=my_collate_fn,\n","                                              shuffle=True,\n","                                              generator=torch.Generator(device))"],"metadata":{"id":"E1r2Z7PqeXDf","executionInfo":{"status":"ok","timestamp":1713978970121,"user_tz":-330,"elapsed":23,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"id":"E1r2Z7PqeXDf","execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"id":"c11ce0fa","metadata":{"id":"c11ce0fa","executionInfo":{"status":"ok","timestamp":1713978974987,"user_tz":-330,"elapsed":4885,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["# load mean, std_dev\n","norm_dict = torch.load('./normalization_tensors/ravdess/pt_w2v2/all_layers_spkr.pt')\n","\n","w2v2_mean = norm_dict['mean']\n","w2v2_std_dev = norm_dict['std_dev']\n","\n","for k in w2v2_mean.keys():\n","    w2v2_mean[k] = w2v2_mean[k].to(device)\n","for k in w2v2_std_dev.keys():\n","    w2v2_std_dev[k] = w2v2_std_dev[k].to(device)"]},{"cell_type":"code","execution_count":14,"id":"6cc6eeae","metadata":{"executionInfo":{"elapsed":3469,"status":"ok","timestamp":1713978991172,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"},"user_tz":-330},"id":"6cc6eeae","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["410ce2716ce040c1901c57c6cc306296","a010d256dc6441dfa56959fc82091796","89931758a1e24f88885034d959d4156a","79c919992f594ec9ad1d6ce3d7eed695","51bec4ee3d9546b5a682b8082f021beb","fc4e3fc88a12447eaebd4e6647052265","a8145927490c44af86b07bb52f03d54a","facaf985b5e84fcb8c30efd1d1e4d56a","e5bf0395beaf4dfd8d6d956c3af49001","d2f325efbaf0432bbccb2e853d3fe019","84619e37e25a428d98329e19adc549e5"]},"outputId":"4adceb41-dab0-4144-fe1a-f2261115a250"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/360M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"410ce2716ce040c1901c57c6cc306296"}},"metadata":{}}],"source":["#        dim:      16,      32,      64,     128\n","#   val_loss: xxxxxxx, xxxxxxx, xxxxxxx, xxxxxxx\n","#    val_acc:   xxxxx,   xxxxx,   xxxxx,   xxxxx\n","# val_recall:   xxxxx,   xxxxx,   xxxxx,   xxxxx\n","# dim1 = 16\n","\n","model = PreTrainedAllLayers(\n","    250,\n","    # dim1,\n","    norm_means=w2v2_mean,\n","    norm_std_devs=w2v2_std_dev,\n",")\n","model.to(device);"]},{"cell_type":"code","execution_count":15,"id":"77196579","metadata":{"id":"77196579","executionInfo":{"status":"ok","timestamp":1713978992438,"user_tz":-330,"elapsed":36,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":16,"id":"ec468d9b","metadata":{"id":"ec468d9b","executionInfo":{"status":"ok","timestamp":1713978992441,"user_tz":-330,"elapsed":30,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[],"source":["lr = 1e-3\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","lr_scheduler = ExponentialLR(optimizer, gamma=0.95)"]},{"cell_type":"code","execution_count":17,"id":"b4b908b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4b908b8","outputId":"1a49f46d-b231-40b0-a161-e1ce165db4c2","scrolled":true,"executionInfo":{"status":"ok","timestamp":1713981836410,"user_tz":-330,"elapsed":2843997,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Before Training, on val set:\n","Test Error:\n","    loss: 1.95935, acc: 7.69 %\n","    avg recall: 14.29 %\n","Before Training, on test set:\n","Test Error:\n","    loss: 1.95928, acc: 7.69 %\n","    avg recall: 14.29 %\n","Starting training\n","Epoch 1\n","--------------------------------\n","loss: 1.91924    [ 256/2036]\n","loss: 1.90991    [ 512/2036]\n","loss: 1.83795    [ 768/2036]\n","loss: 1.73277    [1024/2036]\n","loss: 1.60289    [1280/2036]\n","loss: 1.49459    [1536/2036]\n","loss: 1.54843    [1792/2036]\n","loss: 1.25618    [2036/2036]\n","Test Error:\n","    loss: 1.42441, acc: 50.48 %\n","    avg recall: 39.88 %\n","Epoch 2\n","--------------------------------\n","loss: 1.37063    [ 256/2036]\n","loss: 1.34267    [ 512/2036]\n","loss: 1.22270    [ 768/2036]\n","loss: 1.10349    [1024/2036]\n","loss: 1.20382    [1280/2036]\n","loss: 1.10143    [1536/2036]\n","loss: 1.08567    [1792/2036]\n","loss: 0.90992    [2036/2036]\n","Test Error:\n","    loss: 0.94959, acc: 66.35 %\n","    avg recall: 64.29 %\n","Epoch 3\n","--------------------------------\n","loss: 0.84648    [ 256/2036]\n","loss: 0.80646    [ 512/2036]\n","loss: 0.72102    [ 768/2036]\n","loss: 0.97753    [1024/2036]\n","loss: 0.75464    [1280/2036]\n","loss: 0.60709    [1536/2036]\n","loss: 0.79603    [1792/2036]\n","loss: 0.65926    [2036/2036]\n","Test Error:\n","    loss: 0.71288, acc: 75.00 %\n","    avg recall: 75.60 %\n","Epoch 4\n","--------------------------------\n","loss: 0.59309    [ 256/2036]\n","loss: 0.60909    [ 512/2036]\n","loss: 0.90459    [ 768/2036]\n","loss: 0.50596    [1024/2036]\n","loss: 0.49664    [1280/2036]\n","loss: 0.76598    [1536/2036]\n","loss: 0.62422    [1792/2036]\n","loss: 0.57002    [2036/2036]\n","Test Error:\n","    loss: 0.52472, acc: 77.40 %\n","    avg recall: 75.45 %\n","Epoch 5\n","--------------------------------\n","loss: 0.52257    [ 256/2036]\n","loss: 0.57509    [ 512/2036]\n","loss: 0.43257    [ 768/2036]\n","loss: 0.53465    [1024/2036]\n","loss: 0.56372    [1280/2036]\n","loss: 0.44436    [1536/2036]\n","loss: 0.46376    [1792/2036]\n","loss: 0.54804    [2036/2036]\n","Test Error:\n","    loss: 0.48305, acc: 77.88 %\n","    avg recall: 76.64 %\n","Epoch 6\n","--------------------------------\n","loss: 0.55267    [ 256/2036]\n","loss: 0.54075    [ 512/2036]\n","loss: 0.34562    [ 768/2036]\n","loss: 0.29971    [1024/2036]\n","loss: 0.48803    [1280/2036]\n","loss: 0.44703    [1536/2036]\n","loss: 0.41637    [1792/2036]\n","loss: 0.31182    [2036/2036]\n","Test Error:\n","    loss: 0.48150, acc: 85.10 %\n","    avg recall: 86.16 %\n","Epoch 7\n","--------------------------------\n","loss: 0.48628    [ 256/2036]\n","loss: 0.49361    [ 512/2036]\n","loss: 0.39254    [ 768/2036]\n","loss: 0.28542    [1024/2036]\n","loss: 0.19406    [1280/2036]\n","loss: 0.25067    [1536/2036]\n","loss: 0.30779    [1792/2036]\n","loss: 0.48434    [2036/2036]\n","Test Error:\n","    loss: 0.45356, acc: 80.77 %\n","    avg recall: 78.57 %\n","Epoch 8\n","--------------------------------\n","loss: 0.17494    [ 256/2036]\n","loss: 0.30706    [ 512/2036]\n","loss: 0.22699    [ 768/2036]\n","loss: 0.35469    [1024/2036]\n","loss: 0.32281    [1280/2036]\n","loss: 0.30095    [1536/2036]\n","loss: 0.48318    [1792/2036]\n","loss: 0.21893    [2036/2036]\n","Test Error:\n","    loss: 0.42274, acc: 83.65 %\n","    avg recall: 82.89 %\n","Epoch 9\n","--------------------------------\n","loss: 0.29888    [ 256/2036]\n","loss: 0.35112    [ 512/2036]\n","loss: 0.33904    [ 768/2036]\n","loss: 0.35183    [1024/2036]\n","loss: 0.14456    [1280/2036]\n","loss: 0.24683    [1536/2036]\n","loss: 0.36282    [1792/2036]\n","loss: 0.22571    [2036/2036]\n","Test Error:\n","    loss: 0.53687, acc: 83.17 %\n","    avg recall: 83.04 %\n","Epoch 10\n","--------------------------------\n","loss: 0.26064    [ 256/2036]\n","loss: 0.27099    [ 512/2036]\n","loss: 0.28776    [ 768/2036]\n","loss: 0.22592    [1024/2036]\n","loss: 0.23932    [1280/2036]\n","loss: 0.39449    [1536/2036]\n","loss: 0.20163    [1792/2036]\n","loss: 0.38363    [2036/2036]\n","Test Error:\n","    loss: 0.35649, acc: 86.54 %\n","    avg recall: 87.65 %\n","Epoch 11\n","--------------------------------\n","loss: 0.25694    [ 256/2036]\n","loss: 0.39456    [ 512/2036]\n","loss: 0.26627    [ 768/2036]\n","loss: 0.20323    [1024/2036]\n","loss: 0.20344    [1280/2036]\n","loss: 0.10962    [1536/2036]\n","loss: 0.17340    [1792/2036]\n","loss: 0.24903    [2036/2036]\n","Test Error:\n","    loss: 0.47417, acc: 82.21 %\n","    avg recall: 79.76 %\n","Epoch 12\n","--------------------------------\n","loss: 0.12400    [ 256/2036]\n","loss: 0.20891    [ 512/2036]\n","loss: 0.18210    [ 768/2036]\n","loss: 0.20579    [1024/2036]\n","loss: 0.20418    [1280/2036]\n","loss: 0.20253    [1536/2036]\n","loss: 0.21224    [1792/2036]\n","loss: 0.20448    [2036/2036]\n","Test Error:\n","    loss: 0.37269, acc: 86.54 %\n","    avg recall: 86.01 %\n","Epoch 13\n","--------------------------------\n","loss: 0.25457    [ 256/2036]\n","loss: 0.10069    [ 512/2036]\n","loss: 0.23895    [ 768/2036]\n","loss: 0.14939    [1024/2036]\n","loss: 0.17669    [1280/2036]\n","loss: 0.24756    [1536/2036]\n","loss: 0.16367    [1792/2036]\n","loss: 0.27837    [2036/2036]\n","Test Error:\n","    loss: 0.47009, acc: 85.10 %\n","    avg recall: 84.82 %\n","Epoch 14\n","--------------------------------\n","loss: 0.16323    [ 256/2036]\n","loss: 0.22037    [ 512/2036]\n","loss: 0.25539    [ 768/2036]\n","loss: 0.13900    [1024/2036]\n","loss: 0.21579    [1280/2036]\n","loss: 0.19226    [1536/2036]\n","loss: 0.16829    [1792/2036]\n","loss: 0.11868    [2036/2036]\n","Test Error:\n","    loss: 0.45315, acc: 84.62 %\n","    avg recall: 85.71 %\n","Epoch 15\n","--------------------------------\n","loss: 0.11456    [ 256/2036]\n","loss: 0.14661    [ 512/2036]\n","loss: 0.22617    [ 768/2036]\n","loss: 0.13982    [1024/2036]\n","loss: 0.20544    [1280/2036]\n","loss: 0.10515    [1536/2036]\n","loss: 0.21862    [1792/2036]\n","loss: 0.18986    [2036/2036]\n","Test Error:\n","    loss: 0.44432, acc: 84.13 %\n","    avg recall: 83.78 %\n","Early stopping after 15 epochs\n"]}],"source":["num_epochs = 30\n","patience = 4\n","\n","print(\"Before Training, on val set:\")\n","_ = test_epoch(val_dataloader, num_classes, model, loss_fn)\n","print(\"Before Training, on test set:\")\n","_ = test_epoch(test_dataloader, num_classes, model, loss_fn)\n","\n","print(\"Starting training\")\n","best_loss = float('inf')\n","i = 0\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}\")\n","    print(\"--------------------------------\")\n","    train_epoch(train_dataloader, model, loss_fn, optimizer, 4, lr_scheduler)\n","    loss = test_epoch(val_dataloader, num_classes, model, loss_fn)\n","    if loss < best_loss:\n","        best_loss = loss\n","        torch.save({\n","            \"epochs_done\": epoch+1,\n","            \"model_state_dict\": model.state_dict(),\n","            \"opt_state_dict\": optimizer.state_dict(),\n","            \"val_loss\": loss\n","            }, \"./saved_models/dense/best_pt_all_spkr.pt\")\n","        i = 0\n","    elif loss > best_loss:\n","        i += 1\n","    if i > patience:\n","        print(f\"Early stopping after {epoch+1} epochs\")\n","        break;"]},{"cell_type":"markdown","source":["## Now load the saved model, and check its performance"],"metadata":{"id":"tcTtBP30xI98"},"id":"tcTtBP30xI98"},{"cell_type":"code","source":["loaded_model = PreTrainedAllLayers(\n","    250,\n","    # dim1,\n","    norm_means=w2v2_mean,\n","    norm_std_devs=w2v2_std_dev,\n",")"],"metadata":{"id":"P5vz6h_q3vZa","executionInfo":{"status":"ok","timestamp":1713981883759,"user_tz":-330,"elapsed":2274,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"id":"P5vz6h_q3vZa","execution_count":18,"outputs":[]},{"cell_type":"code","source":["loaded_dict = torch.load(\n","    \"./saved_models/dense/best_pt_all_spkr.pt\",\n","    map_location=device\n",")"],"metadata":{"id":"_PgtOvJe5vYq","executionInfo":{"status":"ok","timestamp":1713981884566,"user_tz":-330,"elapsed":828,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}}},"id":"_PgtOvJe5vYq","execution_count":19,"outputs":[]},{"cell_type":"code","source":["loaded_dict[\"epochs_done\"]"],"metadata":{"id":"_d6BeaVM00Lr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713981884567,"user_tz":-330,"elapsed":20,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"4bbee6ef-3837-4526-cc7b-b2f61bb0dc70"},"id":"_d6BeaVM00Lr","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["loaded_model.load_state_dict(loaded_dict[\"model_state_dict\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyN9n-Tf51jo","executionInfo":{"status":"ok","timestamp":1713981884568,"user_tz":-330,"elapsed":16,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"da65876a-abc0-4b1e-dcf6-22efd234be05"},"id":"PyN9n-Tf51jo","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# On train set\n","test_epoch(train_dataloader, num_classes, loaded_model, loss_fn);"],"metadata":{"id":"0pXkPlWh6k4w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713981953106,"user_tz":-330,"elapsed":68546,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"28199519-d98c-449e-ae0d-9525e4a5490f"},"id":"0pXkPlWh6k4w","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error:\n","    loss: 0.19027, acc: 93.57 %\n","    avg recall: 93.94 %\n"]}]},{"cell_type":"code","source":["# On validation set\n","test_epoch(val_dataloader, num_classes, loaded_model, loss_fn);"],"metadata":{"id":"xpZMvArE6SwU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713981960317,"user_tz":-330,"elapsed":7232,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"24a774ea-b257-408c-a3f2-114475571cff"},"id":"xpZMvArE6SwU","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error:\n","    loss: 0.40250, acc: 86.54 %\n","    avg recall: 87.65 %\n"]}]},{"cell_type":"code","source":["# On test set\n","test_epoch(test_dataloader, num_classes, loaded_model, loss_fn);"],"metadata":{"id":"pHMdtm0K55Mw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713981968386,"user_tz":-330,"elapsed":8087,"user":{"displayName":"Adbhut Bhardwaj","userId":"06043960542338281847"}},"outputId":"4bd628ec-039a-4b12-de23-c7755f52d04e"},"id":"pHMdtm0K55Mw","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error:\n","    loss: 0.55501, acc: 81.73 %\n","    avg recall: 83.48 %\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GIiKRIkg6eZ1"},"id":"GIiKRIkg6eZ1","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"interpreter":{"hash":"b68ef2f5be75b4d475511982f31ad7ed227759d712d8ff8b40fbbe531d2fd5d8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"410ce2716ce040c1901c57c6cc306296":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a010d256dc6441dfa56959fc82091796","IPY_MODEL_89931758a1e24f88885034d959d4156a","IPY_MODEL_79c919992f594ec9ad1d6ce3d7eed695"],"layout":"IPY_MODEL_51bec4ee3d9546b5a682b8082f021beb"}},"a010d256dc6441dfa56959fc82091796":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc4e3fc88a12447eaebd4e6647052265","placeholder":"​","style":"IPY_MODEL_a8145927490c44af86b07bb52f03d54a","value":"100%"}},"89931758a1e24f88885034d959d4156a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_facaf985b5e84fcb8c30efd1d1e4d56a","max":377565405,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5bf0395beaf4dfd8d6d956c3af49001","value":377565405}},"79c919992f594ec9ad1d6ce3d7eed695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2f325efbaf0432bbccb2e853d3fe019","placeholder":"​","style":"IPY_MODEL_84619e37e25a428d98329e19adc549e5","value":" 360M/360M [00:03&lt;00:00, 140MB/s]"}},"51bec4ee3d9546b5a682b8082f021beb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc4e3fc88a12447eaebd4e6647052265":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8145927490c44af86b07bb52f03d54a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"facaf985b5e84fcb8c30efd1d1e4d56a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5bf0395beaf4dfd8d6d956c3af49001":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2f325efbaf0432bbccb2e853d3fe019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84619e37e25a428d98329e19adc549e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}